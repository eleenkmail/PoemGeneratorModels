{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "import pandas as pd\n",
    "import pyarabic.araby as araby\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['h.5.attn.masked_bias', 'h.0.attn.masked_bias', 'h.6.attn.masked_bias', 'h.8.attn.masked_bias', 'h.1.attn.masked_bias', 'h.10.attn.masked_bias', 'h.7.attn.masked_bias', 'h.4.attn.masked_bias', 'h.3.attn.masked_bias', 'h.9.attn.masked_bias', 'h.11.attn.masked_bias', 'h.2.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load pretrained GPT-2 model and tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"aubmindlab/aragpt2-base\")\n",
    "model = TFGPT2LMHeadModel.from_pretrained(\"aubmindlab/aragpt2-base\",from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>poet_name</th>\n",
       "      <th>poem_title</th>\n",
       "      <th>poem_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22523</th>\n",
       "      <td>22697</td>\n",
       "      <td>العصر العباسي</td>\n",
       "      <td>الأحنف العكبري</td>\n",
       "      <td>تنبه أيها</td>\n",
       "      <td>تنبّه أيّها\\nوصمّم إن طول النوم عار\\nتوقر عن م...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52032</th>\n",
       "      <td>52206</td>\n",
       "      <td>العصر المملوكي</td>\n",
       "      <td>صفي الدين الحلي</td>\n",
       "      <td>لي صديق لا يعرف الصدق في القو</td>\n",
       "      <td>لي صَديقٌ لا يَعرِفُ الصِدقَ في القَو\\nلِ وَلي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27467</th>\n",
       "      <td>27641</td>\n",
       "      <td>العصر الايوبي</td>\n",
       "      <td>القاضي الفاضل</td>\n",
       "      <td>سأل اللوى وسؤاله تعليل</td>\n",
       "      <td>سَأَلَ اللوى وَسُؤالُهُ تَعليلُ\\nوَمِنَ المُحا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41268</th>\n",
       "      <td>41442</td>\n",
       "      <td>العصر الاموي</td>\n",
       "      <td>ذو الرمة</td>\n",
       "      <td>بيضاء صفراء قد تنازعها</td>\n",
       "      <td>بَيضاءُ صَفراءُ قَد تَنازَعَها\\nلَونانِ مِن فِ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39589</th>\n",
       "      <td>39763</td>\n",
       "      <td>العصر الاموي</td>\n",
       "      <td>جرير</td>\n",
       "      <td>بحري قومي هيجي الأحزانا</td>\n",
       "      <td>بَحَرِيَّ قومي هَيِّجي الأَحزانا\\nوَاِستَعجِلِ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1777</th>\n",
       "      <td>1884</td>\n",
       "      <td>العراق</td>\n",
       "      <td>بهاء الدين الصيادي</td>\n",
       "      <td>إذا ما صغت في المحبوب نظما</td>\n",
       "      <td>إذا ما صِغْتُ في المَحْبوبِ نَظْماً\\nيُساعِدُن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15783</th>\n",
       "      <td>15957</td>\n",
       "      <td>العصر العباسي</td>\n",
       "      <td>ابن الرومي</td>\n",
       "      <td>أيسير مدحي في الأمير وكله</td>\n",
       "      <td>أيسيرُ مدحي في الأمير وكلُّهُ\\nيا للرجال مُؤرّ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51020</th>\n",
       "      <td>51194</td>\n",
       "      <td>العصر المملوكي</td>\n",
       "      <td>لسان الدين بن الخطيب</td>\n",
       "      <td>لم يبق لي جود الولاية حاجة</td>\n",
       "      <td>لَمْ يُبْقِ لِي جُودُ الْوِلايَةِ حَاجَةً\\nفِي...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8044</th>\n",
       "      <td>8217</td>\n",
       "      <td>لبنان</td>\n",
       "      <td>أبو الفضل الوليد</td>\n",
       "      <td>ليالي النوى حتام ترخين برقعا</td>\n",
       "      <td>ليالي النّوى حتّامَ ترخينَ برقعا\\nلينتابني ذكر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54795</th>\n",
       "      <td>54969</td>\n",
       "      <td>العصر المملوكي</td>\n",
       "      <td>ابن زمرك</td>\n",
       "      <td>يا أيها المولى الذي أيامه</td>\n",
       "      <td>يا أيها المولى الذي أيامه\\nتهمي بسحب الجود من ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        category             poet_name  \\\n",
       "22523  22697   العصر العباسي        الأحنف العكبري   \n",
       "52032  52206  العصر المملوكي       صفي الدين الحلي   \n",
       "27467  27641   العصر الايوبي         القاضي الفاضل   \n",
       "41268  41442    العصر الاموي              ذو الرمة   \n",
       "39589  39763    العصر الاموي                  جرير   \n",
       "...      ...             ...                   ...   \n",
       "1777    1884          العراق    بهاء الدين الصيادي   \n",
       "15783  15957   العصر العباسي            ابن الرومي   \n",
       "51020  51194  العصر المملوكي  لسان الدين بن الخطيب   \n",
       "8044    8217           لبنان      أبو الفضل الوليد   \n",
       "54795  54969  العصر المملوكي              ابن زمرك   \n",
       "\n",
       "                          poem_title  \\\n",
       "22523                      تنبه أيها   \n",
       "52032  لي صديق لا يعرف الصدق في القو   \n",
       "27467         سأل اللوى وسؤاله تعليل   \n",
       "41268         بيضاء صفراء قد تنازعها   \n",
       "39589        بحري قومي هيجي الأحزانا   \n",
       "...                              ...   \n",
       "1777      إذا ما صغت في المحبوب نظما   \n",
       "15783      أيسير مدحي في الأمير وكله   \n",
       "51020     لم يبق لي جود الولاية حاجة   \n",
       "8044    ليالي النوى حتام ترخين برقعا   \n",
       "54795      يا أيها المولى الذي أيامه   \n",
       "\n",
       "                                               poem_text  \n",
       "22523  تنبّه أيّها\\nوصمّم إن طول النوم عار\\nتوقر عن م...  \n",
       "52032  لي صَديقٌ لا يَعرِفُ الصِدقَ في القَو\\nلِ وَلي...  \n",
       "27467  سَأَلَ اللوى وَسُؤالُهُ تَعليلُ\\nوَمِنَ المُحا...  \n",
       "41268  بَيضاءُ صَفراءُ قَد تَنازَعَها\\nلَونانِ مِن فِ...  \n",
       "39589  بَحَرِيَّ قومي هَيِّجي الأَحزانا\\nوَاِستَعجِلِ...  \n",
       "...                                                  ...  \n",
       "1777   إذا ما صِغْتُ في المَحْبوبِ نَظْماً\\nيُساعِدُن...  \n",
       "15783  أيسيرُ مدحي في الأمير وكلُّهُ\\nيا للرجال مُؤرّ...  \n",
       "51020  لَمْ يُبْقِ لِي جُودُ الْوِلايَةِ حَاجَةً\\nفِي...  \n",
       "8044   ليالي النّوى حتّامَ ترخينَ برقعا\\nلينتابني ذكر...  \n",
       "54795  يا أيها المولى الذي أيامه\\nتهمي بسحب الجود من ...  \n",
       "\n",
       "[500 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the data \n",
    "data = pd.read_csv('Arabic_poetry_dataset.csv')\n",
    "# shuffle the data \n",
    "data = data.sample(frac=1)\n",
    "# select the first 500 rows\n",
    "data = data.sample(500)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the poems into a list\n",
    "lines = data['poem_text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'لي صَديقٌ لا يَعرِفُ الصِدقَ في القَو\\nلِ وَليسَ الصَديقُ إِلّا الصَدوقُ\\nلَيسَ فيهِ تَصَوُّرٌ يُدرِكُ العِل\\nمَ وَلا لي إِن قُلتُهُ تَصديقُ'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وصمّم إن طول النوم عار'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join all poems into one string\n",
    "lines = \"\\n\".join(lines)\n",
    "# split the string into a list of lines\n",
    "lines = lines.split(\"\\n\")\n",
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12148"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove diacritics from the lines\n",
    "lines = [araby.strip_diacritics(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the lines into sequences of tokens\n",
    "tokenized_lines = [tokenizer.encode(line, add_special_tokens=True) for line in lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'وصمم إن طول النوم عار'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1257, 1765, 588, 5951, 6059, 16046]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate input sequences and labels\n",
    "input_sequences = [line[:-1] for line in tokenized_lines]\n",
    "labels = [line[1:] for line in tokenized_lines]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1257, 1765, 588, 5951, 6059]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1765, 588, 5951, 6059, 16046]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the maximum sequence length\n",
    "seq_max_length = max(len(seq) for seq in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the maximum label length\n",
    "label_max_length = max(len(seq) for seq in labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences to the maximum length\n",
    "padded_sequences = pad_sequences(input_sequences, maxlen=seq_max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_labels = pad_sequences(labels, maxlen=label_max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3614,   949,     0, ...,     0,     0,     0],\n",
       "       [ 1257,  1765,   588, ...,     0,     0,     0],\n",
       "       [  273, 61067,   394, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  273, 12026, 23179, ...,     0,     0,     0],\n",
       "       [23475,   601, 42163, ...,     0,     0,     0],\n",
       "       [ 2840,  5829, 43347, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  949,  7085,     0, ...,     0,     0,     0],\n",
       "       [ 1765,   588,  5951, ...,     0,     0,     0],\n",
       "       [61067,   394,   224, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [12026, 23179, 62076, ...,     0,     0,     0],\n",
       "       [  601, 42163,   284, ...,     0,     0,     0],\n",
       "       [ 5829, 43347,   537, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input sequences and labels to TensorFlow datasets\n",
    "input_dataset = tf.data.Dataset.from_tensor_slices(padded_sequences)\n",
    "labels_dataset = tf.data.Dataset.from_tensor_slices(padded_labels)\n",
    "\n",
    "# Combine input and label datasets\n",
    "dataset = tf.data.Dataset.zip((input_dataset, labels_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "729/729 [==============================] - 168s 212ms/step - loss: 1.1721 - accuracy: 0.8576\n",
      "Epoch 2/3\n",
      "729/729 [==============================] - 153s 210ms/step - loss: 1.0342 - accuracy: 0.8650\n",
      "Epoch 3/3\n",
      "729/729 [==============================] - 154s 211ms/step - loss: 0.9973 - accuracy: 0.8663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dfb3391988>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle and batch the dataset\n",
    "batch_size = 16\n",
    "dataset = dataset.shuffle(buffer_size=len(input_sequences))\n",
    "dataset = dataset.batch(batch_size)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n",
    "\n",
    "# Fine-tuning\n",
    "model.fit(dataset, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "seed_test= \"وحلفت ان\"\n",
    "input_ids = tokenizer.encode(seed_test, return_tensors='tf')\n",
    "sample_outputs = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    max_length=50,\n",
    "    top_k=0,\n",
    "    top_p=0.9,\n",
    "    temperature=0.8,\n",
    "    num_return_sequences=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: وحلف انك لا تخون عدوا لك وإن كنتم لا تخون عدوا بل عدوا فعقابكم عليه ومن عاداهم فلا تخون بهم عدوهم وإن كنت عدوا فانقصوا العهد واجمعوا على قود الأعداء وأنوكوا على مقودهم\n"
     ]
    }
   ],
   "source": [
    "print(\"Output:\", tokenizer.decode(sample_outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt2_tokenizer_fine_tuned_model_arabic\\\\tokenizer_config.json',\n",
       " 'gpt2_tokenizer_fine_tuned_model_arabic\\\\special_tokens_map.json',\n",
       " 'gpt2_tokenizer_fine_tuned_model_arabic\\\\vocab.json',\n",
       " 'gpt2_tokenizer_fine_tuned_model_arabic\\\\merges.txt',\n",
       " 'gpt2_tokenizer_fine_tuned_model_arabic\\\\added_tokens.json')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "model.save_pretrained('gpt2_fine_tuned_model_arabic')\n",
    "# save tokenizer\n",
    "tokenizer.save_pretrained('gpt2_tokenizer_fine_tuned_model_arabic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
